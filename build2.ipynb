{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, UpSampling2D, Input\n",
    "from keras.models import Model, Sequential\n",
    "#from keras.utils import img_to_array, to_categorical\n",
    "#from tensorflow.keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras import optimizers\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from keras.layers import Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"C:\\\\Users\\\\user\\\\PycharmProjects\\\\pythonProject\\\\datasets\\\\new\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_img_to_tensor(fpath):\n",
    "    img = cv2.imread(fpath)\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    return img_to_array(img)\n",
    "\n",
    "# Load dataset and label data\n",
    "def get_img_data_and_label(root_dir):\n",
    "    image_dataset = []\n",
    "    image_label = []\n",
    "    classes = listdir(root_dir)\n",
    "    class_mapping = {c: i for i, c in enumerate(classes)}\n",
    "\n",
    "    for cls in classes:\n",
    "        skin_img_list = listdir(f\"{root_dir}/{cls}\")\n",
    "        for imgfile in skin_img_list:\n",
    "            filepath = f\"{root_dir}/{cls}/{imgfile}\"\n",
    "            image_dataset.append(convert_img_to_tensor(filepath))\n",
    "            image_label.append(class_mapping[cls])\n",
    "    \n",
    "    return image_dataset, image_label, len(classes), classes\n",
    "\n",
    "image_dataset, image_labels, no_of_output_layer, classes = get_img_data_and_label(root_dir)\n",
    "\n",
    "# Normalize and reshape data\n",
    "image_dataset = np.array(image_dataset, dtype=np.float32) / 255.0\n",
    "image_dataset = image_dataset.reshape(-1, 256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (256, 256, 3)\n",
    "autoencoder = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "\n",
    "    # Encoder to bottleneck\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),  # This will be the bottleneck layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='relu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "\n",
    "# Define input shape\n",
    "input_img = Input(shape=(256, 256, 3))\n",
    "\n",
    "# Encoder\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# Decoder\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# Autoencoder\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Load and preprocess images\n",
    "# resized_images = ...\n",
    "\n",
    "# Train the autoencoder\n",
    "# autoencoder.fit(resized_images, resized_images, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 256, 256, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 128, 128, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 128, 128, 128)     73856     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 64, 64, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 128, 128, 128)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 128, 128, 128)     147584    \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSampling  (None, 256, 256, 128)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 256, 256, 64)      73792     \n",
      "                                                                 \n",
      " up_sampling2d_3 (UpSampling  (None, 512, 512, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 512, 512, 3)       1731      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 298,755\n",
      "Trainable params: 298,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, UpSampling2D, MaxPooling2D\n",
    "from keras.models import Model\n",
    "\n",
    "# Encoder\n",
    "input_img = Input(shape=(256, 256, 3))\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# Decoder\n",
    "x = UpSampling2D((2, 2))(encoded)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# Combine encoder and decoder into an autoencoder model\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 256, 256, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 128, 128, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 128, 128, 128)     73856     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 64, 64, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " up_sampling2d_4 (UpSampling  (None, 128, 128, 128)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 128, 128, 128)     147584    \n",
      "                                                                 \n",
      " up_sampling2d_5 (UpSampling  (None, 256, 256, 128)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 256, 256, 64)      73792     \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 256, 256, 3)       1731      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 298,755\n",
      "Trainable params: 298,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, UpSampling2D, MaxPooling2D\n",
    "from keras.models import Model\n",
    "\n",
    "# Encoder\n",
    "input_img = Input(shape=(256, 256, 3))\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)  # Now shape is (64, 64, 128)\n",
    "\n",
    "# Decoder\n",
    "x = UpSampling2D((2, 2))(encoded)  # Now shape is (128, 128, 128)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)  # Now shape is (256, 256, 128)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)  # Now shape is (256, 256, 3)\n",
    "\n",
    "# Combine encoder and decoder into an autoencoder model\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "34/34 [==============================] - 577s 17s/step - loss: 0.3634 - val_loss: 0.1386\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 547s 16s/step - loss: 0.2407 - val_loss: 0.1226\n",
      "Epoch 3/10\n",
      "26/34 [=====================>........] - ETA: 2:01 - loss: 0.2288"
     ]
    }
   ],
   "source": [
    "# Assuming `image_dataset` is your dataset\n",
    "autoencoder.fit(image_dataset, image_dataset, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract encoder model\n",
    "encoder_model = Model(autoencoder.input, autoencoder.layers[8].output)  # The bottleneck layer is the eighth layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract encoded features\n",
    "encoded_features = encoder_model.predict(image_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train-test split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(encoded_features, image_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "ytrain = to_categorical(ytrain, no_of_output_layer)\n",
    "ytest = to_categorical(ytest, no_of_output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification model using the autoencoder's encoded features\n",
    "classification_model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(64,)),\n",
    "    Dense(no_of_output_layer, activation='softmax')\n",
    "])\n",
    "\n",
    "classification_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the classification model\n",
    "classifier_history = classification_model.fit(xtrain, ytrain, epochs=10, batch_size=32, validation_data=(xtest, ytest), verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and visualize results\n",
    "ypred = classification_model.predict(xtest)\n",
    "ytest_argmax = np.argmax(ytest, axis=1)\n",
    "ypred_argmax = np.argmax(ypred, axis=1)\n",
    "\n",
    "print(classification_report(ytest_argmax, ypred_argmax, target_names=classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy and loss\n",
    "acc = classifier_history.history['accuracy']\n",
    "val_acc = classifier_history.history['val_accuracy']\n",
    "loss = classifier_history.history['loss']\n",
    "val_loss = classifier_history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(ytest_argmax, ypred_argmax)\n",
    "sns.heatmap(cm, annot=True, fmt='g', xticklabels=classes, yticklabels=classes)\n",
    "plt.ylabel('Predicted')\n",
    "plt.xlabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
